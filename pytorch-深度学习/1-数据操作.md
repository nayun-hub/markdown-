# 数据操作

## 1. 创建tensor

```python
torch.empty(a, b)	# 返回一个充满未初始化数据的张量。
```

```python
torch.rand(a, b)	# 返回一个随机初始化张量
```

```python
torch.zeros(a, b)	# 返回一个全为0的初始化张量
```

```python
torch.tensor([x1, x2, ...])		# 直接根据数据创建
```

```python
torch.randn_like(x, dtype=None)	# 创建一个跟x相同大小的随机张量
```

可以通过shape或者size()获取Tensor的形状

```python
torch.eye(*size)	# 生成对角线为1，其余为0的张量
```

```python
torch.arange(s, e, steps)	# 从s到e，步长为step
```

```python
torch.linspace(s, e, steps)	# 从s到e，生成setps份
```

```python
rand/randn(*sizes)	# 均匀/标准分布
```

```python
normal(mean,std)/uniform(from, to)	# 正态/均匀分布
```

这些方法都可以指定数据类型dtype和存放device

## 2. 操作



### 算术操作

* 加法形式1

  ```python
  y = torch.rand(5, 3)
  print(x + y)
  ```

* 加法形式2

  ```python
  print(torch.add(x, y))  或
  torch.add(x, y, out=result)
  ```

* 加法形式3、inplace

  ```python
  y.add_(x)
  print(y)
  ```

  

### 索引

!!!**索引出来的结果与原数据共享内存**

```python
x = torch.rand(3, 5)
print(x)
y = x[0, :]
print(y)
y += 1
print(y)
```

输出

```python
tensor([[0.1059, 0.3453, 0.3127, 0.5153, 0.1504],
        [0.4183, 0.1678, 0.8960, 0.3427, 0.2044],
        [0.5320, 0.0686, 0.1398, 0.1580, 0.9174]])
tensor([0.1059, 0.3453, 0.3127, 0.5153, 0.1504])
tensor([1.1059, 1.3453, 1.3127, 1.5153, 1.1504])
```

其他索引函数

```python
index_select(input, dim, index)		# 指定维度上选取
# 示例
index = torch.LongTensor([1, 2])
x = torch.arange(24).reshape(2, 3, 4)
y = torch.index_select(x, 1, index)
print(x)
print(y)
# 输出
tensor([[[ 0,  1,  2,  3],
         [ 4,  5,  6,  7],
         [ 8,  9, 10, 11]],

        [[12, 13, 14, 15],
         [16, 17, 18, 19],
         [20, 21, 22, 23]]])
tensor([[[ 4,  5,  6,  7],
         [ 8,  9, 10, 11]],

        [[16, 17, 18, 19],
         [20, 21, 22, 23]]])
```

```python
masked_select(input, mask)			# 使用ByteTensor进行选取

```

```python
non_zero(input)						# 非0元素的下标
```

```python
gather(input, dim, index)			# 根据index，在dim上选取数据，输出size和index一样
```



###  改变形状

**用view() 来改变Tensor的形状**

```python
x = torch.rand(3, 5)
y = x.view(15)
z = x.view(-1, 5)
print(x.size(), y.size(), z.size())
# 输出
torch.Size([3, 5]) torch.Size([15]) torch.Size([3, 5])
```

**返回的新Tensor与源Tensor共享内存**

*若想保留副本，则先使用clone()创造一个副本，然后再使用view()*

函数 item() ，可以将tensor转换成python number

```python
x = torch.randn(1)
print(x)
print(x.item())
# 输出
tensor([-0.3660])
-0.3660127520561218
```

### 线性代数

|     函数     |           功能           |
| :----------: | :----------------------: |
|    trace     |      对角线元素之和      |
|     diag     |        对角线元素        |
|  triu/tril   |      矩阵上/下三角       |
|    mm/bmm    | 矩阵乘法/batch的矩阵乘法 |
| addmm/addbmm |         矩阵运算         |
|      t       |           转置           |
|  dot/cross   |        内积/外积         |
|   inverse    |         求逆矩阵         |

## 广播机制

当对两个形状不同的Tensor按元素运算时，可能会触发**广播机制**（broadcasting）:先适当复制元素使这两个Tensor形状相同后再按元素运算。

```python
x = torch.arange(1, 3).view(1, 2)
y = torch.arange(1, 4).view(3, 1)
print(x)
print(y)
print(x + y)
# 输出
tensor([[1, 2]])
tensor([[1],
        [2],
        [3]])
tensor([[2, 3],
        [3, 4],
        [4, 5]])
```

> x中会将第一行复制到第2、3行，y会将第1列复制到第2列

## 内存开销

判断方法：使用python自带的id()函数，如果两个实例的ID一致，那么对应内存地址相同。

```python
x = torch.tensor([1, 3])
y = torch.tensor([3, 4])
id_pre = id(y)
y = x + y
print(id(y) == id_pre)
# 输出
False
```

> 可以看到内存地址发生了改变

解决办法

法一：通过索引[:]写进y对应内存中

```python
x = torch.tensor([1, 3])
y = torch.tensor([3, 4])
id_pre = id(y)
y[:] = x + y
print(id(y) == id_pre)
# 输出
True
```

法二：使用运算符全名函数中的out参数 或 自加运算符 或 add_()

```python
x = torch.tensor([1, 3])
y = torch.tensor([3, 4])
id_pre = id(y)
torch.add(x, y, out=y)	# y += x, y.add_(x)
print(id(y) == id_pre)
# 输出
True
```

## Tensor和numpy相互转换

Tensor --->  numpy

```python
a = torch.ones(1, 3)
b = a.numpy()
print(a, b)
# 输出
tensor([[1., 1., 1.]]) [[1. 1. 1.]]
```

numpy --> Tensor

```python
import numpy as np

a = np.ones(3)
b = torch.from_numpy(a)
print(a, b)
# 输出
[1. 1. 1.] tensor([1., 1., 1.], dtype=torch.float64)
```

## ON GPU

用to()可以将Tensor在CPU和GPU之间相互移动

```python
if torch.cuda.is_available():
    device = torch.device("cuda")
    y = torch.ones_like(x, device=device)
    x = x.to(device)
    z = x+y
    print(z)
    print(z.to("cpu", torch.double))
 # 输出
tensor([2, 4], device='cuda:0')
tensor([2., 4.], dtype=torch.float64)
```

